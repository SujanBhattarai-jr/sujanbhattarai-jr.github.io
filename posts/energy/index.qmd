---
title: "Predicting CO2 Emission in Nepal: An In-Depth Analysis"
Date : "2023-08-25"
format:
  html:
    toc: true
    html-math-method: katex
    css: /featured_style_projects.css
author:
  - name: Sujan Bhattarai
categories: [Data analysis] # self-defined categories
draft: false # setting this to `true` will prevent your post from appearing on your listing page until you're ready!
editor: 
  markdown: 
    wrap: 72
engine: knitr
---

### Introduction

Sustainable energy is a critical component in addressing global
challenges such as climate change and achieving sustainable development
goals. In this data analysis, we delve into the global dataset on
sustainable energy spanning from 2000 to 2020, with a specific focus on
Nepal. Our aim is to understand energy trends, explore potential use
cases, and employ predictive modeling to forecast CO2 emissions in
Nepal.

## Data Source

```{r, include=FALSE}
#hide all warnings and messages
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

The dataset used in this analysis is sourced from Kaggle. You can find
the dataset
[here](link:%20https://www.kaggle.com/datasets/anshtanwar/global-data-on-sustainable-energy)

```{r  message=FALSE, warning=FALSE}
##load all required libraries
library(tidyverse)
library(here)
library(janitor)
library(rnaturalearth)
library(sf)
library(kableExtra)
```

### Data Cleaning

Data cleaning is an essential step in data analysis. We begin by reading the "energy_data.csv" file and calculating the total count of missing values for each column in the dataset. We then check for and report any duplicated rows in the dataset. The data types of each column are inspected to ensure consistency.

```{r  message=FALSE, warning=FALSE, collapse=TRUE}
##read the energy data
energy_data <- read_csv("energy_data.csv")
data.frame(total_NA_count = colSums(is.na(energy_data)))
```

```{r, collapse = TRUE}
sum(duplicated(energy_data)) 
```

```{r, collapse = TRUE}
##build function to check columns class iteratively
x <- c()
for (i in seq_along(energy_data)){
     x = append(x, class(energy_data[[i]]))
}

```

To ensure consistency, we convert character columns to factors and numeric columns to appropriate numeric types. This step is crucial for ensuring the dataset's readiness for subsequent analysis.

```{r}
#Data-type is in correct format except for country. 
#Change the column type

for (i in seq_along(energy_data)){
  if(class(energy_data[[i]]) == "character"){
    energy_data[[i]] = as.factor(energy_data[[i]])
  }else
    energy_data[[i]] = as.numeric(energy_data[[i]])
}
```

Next, I shorten the column names for ease of reference and plotting. The new column names are more concise and user-friendly, facilitating clearer data visualization and interpretation.

```{r}
#Shorten the column names, useful when plotting and also #refferint to the columns
energy_data1 <- energy_data %>%
  rename( popElectric = "Access to electricity (% of population)",
          cleanfuels = "Access to clean fuels for cooking",
          renewable_elec_cap =  "Renewable-electricity-generating-capacity-per-capita",
          finance_flow = "Financial flows to developing countries (US $)",
          renewable_inTotal= "Renewable energy share in the total final energy consumption (%)",
          fossil_eng= "Electricity from fossil fuels (TWh)",
          n_elece = "Electricity from nuclear (TWh)",
          electric = "Low-carbon electricity (% electricity)",
          electric_re = "Electricity from renewables (TWh)",
          energy_cap = "Primary energy consumption per capita (kWh/person)",
          energy_in = "Energy intensity level of primary energy (MJ/$2017 PPP GDP)",
          co2_emis = "Value_co2_emissions_kt_by_country",
          renewables = "Renewables (% equivalent primary energy)",
          gdp = "gdp_growth",
          gdp_cap = "gdp_per_capita",
          pop_density = "Density\\n(P/Km2)",
          land_area = "Land Area(Km2)",
          Lat = "Latitude",
          Lon = "Longitude")
```

The initial code chunk generates a world map using the ne_countries function, presenting countries at a medium scale. The resulting map is created using the ggplot package with the geom_sf function, providing a visual representation of global geography.

```{r}
world_map <- ne_countries(returnclass = "sf", scale = "medium")
map <- world_map %>% 
       ggplot() +
       geom_sf()
```

I perform a right join between the world map data and the processed energy data (energy_data1) based on the country ID (sovereignt and Entity). The resulting joined dataset is then filtered to include only the data for the year 2020. For each variable from the year to population density, individual maps are created and displayed using the geom_sf function. These maps offer a spatial representation of the selected variable across countries, aiding in the identification of patterns or disparities.

```{r  message=FALSE, warning=FALSE}
joined <- right_join(world_map, energy_data1, by=c("sovereignt"="Entity")) %>% 
          filter(Year == 2020)

for (i in which(colnames(joined) == "Year"):which(colnames(joined) == "pop_density")){
  map_var <- colnames(joined)[i + 1]
  map_plot <- world_map %>%
    st_transform(crs = "+proj=robin") %>%
    ggplot() +
    geom_sf(color = "darkgrey") +
    geom_sf(data = joined, aes(fill = joined[[i + 1]])) +
    labs(x = map_var, fill = map_var) +
    theme_minimal() +
    theme(legend.title = element_blank())
  print(map_plot)
}

```

### Exploring Correlations
I explore the correlation between variables in the processed energy dataset (energy_data1). The correlation matrix is visualized as a heatmap using the ggplot package, with colors ranging from blue (indicating lower correlation) to orange (indicating higher correlation). This analysis helps assess the degree of association between different energy-related variables, providing insights into potential multicollinearity.

```{r}
# Plot the correlation between all variables 
data_for_correlation <- as.matrix(energy_data1[10:length(energy_data1)])

corelation_matrix <- reshape2::melt(
  round(cor(data_for_correlation, use = 'pairwise.complete.obs'), 2)
)

ggplot(data = corelation_matrix, aes(Var1, Var2)) + 
  geom_tile(aes(fill = value)) + 
  scale_fill_gradient(low = "blue", high = "orange") + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

```

### Focus on Nepal
I narrow our focus to Nepal by filtering the energy data for this specific country. A series of line graphs is then generated to visualize the general trends of various energy-related variables in Nepal from 2000 to 2020. These visualizations offer an overview of the country's energy landscape over the selected time period.

```{r}
#filter only for Nepal
# Filter only for Nepal
nepal_energy_data <- energy_data %>% filter(Entity == "Nepal")

# Observe the general trend for all variables
for (i in which(colnames(nepal_energy_data) == "Year"):which(colnames(nepal_energy_data) == "Density\\n(P/Km2)")){
  graph <- ggplot(nepal_energy_data, aes(Year, nepal_energy_data[[i]])) +
    geom_line() +
    labs(x = "Year", y = colnames(nepal_energy_data)[i]) +
    theme_bw()
  print(graph)
}

```

Column with all NA and pop density has same data for two decades . Both
of them can be removed.

1.  **Energy Consumption Prediction:** Predict future energy usage, aid
    planning, and track SDG 7 progress

    Create the regression model

    Co2 emission as a function of energy use and other variables, select
    required variables only using domain knowledge

    Nepal_energy_data\$Value_co2_emissions_kt_by_country \~
    nepal_energy_data\$\`Access to electricity (% of population)\`:
    nepal_energy_data\$\`Energy intensity level of primary energy
    (MJ/\$2017 PPP GDP)\`

Step 1: rearrange the columns

```{r}
nepal_energy_data <- nepal_energy_data %>% 
                     select(Year, `Value_co2_emissions_kt_by_country`, 
                            `Access to electricity (% of population)`: `Energy intensity level of primary energy (MJ/$2017 PPP GDP)`)
```

step 2: **Step wise regression**: see if all variables are predictors for
CO2 emission

```{r}
intercept_only <- lm(`Value_co2_emissions_kt_by_country` ~ 1, 
                      data=nepal_energy_data)

#define model with all predictors
all <- lm(`Value_co2_emissions_kt_by_country` ~ ., 
           data=nepal_energy_data)

#perform forward stepwise regression
forward <- step(intercept_only, direction="both" , 
                scope=formula(all), trace=0)

kableExtra:: kable(forward$anova)
kableExtra:: kable(forward$coefficients)

```
### Feature selection

result from step-wise regression shows that only six variables are
significant in defining co2 emission. this could be wrong but I believe
in statistics though its seldom correct. So, keep only those columns

```{r}
nepal_feature_selected_data  <- nepal_energy_data %>% 
        select(Year,
Co2_emission = `Value_co2_emissions_kt_by_country`, 
Energy_perCap = `Primary energy consumption per capita (kWh/person)`,
renewble_fraction = `Renewable energy share in the total final energy consumption (%)`, 
electricity_perCap = `Renewable-electricity-generating-capacity-per-capita`,
low_carbon_electricity = `Low-carbon electricity (% electricity)`,
energy_intensity = `Energy intensity level of primary energy (MJ/$2017 PPP GDP)`
)

```

### Model Building
Split the data into test and train model

```{r}
set.seed(123)
smp_size <- floor(0.75 * nrow(nepal_feature_selected_data))

## set the seed to make your partition reproducible
set.seed(123)
train_ind <- sample(seq_len(nrow(nepal_feature_selected_data)), size = smp_size)

train <- nepal_feature_selected_data[train_ind, ]
test <-  nepal_feature_selected_data[-train_ind, ] 
```

Fit the linear regression model on train data

```{r}
lm_model <- lm(data = train,
                   Co2_emission ~ (`Energy_perCap` +
                                     renewble_fraction + 
                                     electricity_perCap +
                                     low_carbon_electricity + 
                                     energy_intensity))
summary(lm_model)
t(broom::glance(lm_model)) ##glance creates in long columns, transpose changes it to one column format
```

### Model Evaluation

```{r}
train["model_predict"] <- predict(lm_model, train)

ggplot(train, aes(Year, Co2_emission))+
  geom_line()+
  geom_line(aes(Year, model_predict), color="green")
```

Linear model has high accuracy for the data set. Now use the same model
to forecast the co2 consumption for next 10 years.

Use mathematic metrics MAE to check the accuracy of the model

```{r}
MAE <- (1/nrow(train))*sum((train$model_predict- train$Co2_emission), na.rm = TRUE)
print(MAE)
```

### Conclusion
The MAE calculation gave output a number. It's hard to interpret.
Normalize it between 0 to 1, so that low values of MAE is the best fit

```{r}
range_actual <- max(train$Co2_emission, na.rm = TRUE) - min(train$Co2_emission, 
                                                            na.rm=TRUE)
# Normalize MAE
normalized_MAE <- (MAE/range_actual)
normalized_MAE

##shorcut to measure more accuracy metrics
forecast:: accuracy(train$Co2_emission, train$model_predict)
```
